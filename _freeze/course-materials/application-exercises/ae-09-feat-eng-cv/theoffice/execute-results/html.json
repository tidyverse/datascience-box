{
  "hash": "069d3ac17d38facb6f4d632e8f6bf4b1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The Office\"\nauthor: \"Mine Çetinkaya-Rundel\"\nformat: html\neditor: visual\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(schrute)\nlibrary(lubridate)\n```\n:::\n\n\nUse `theoffice` data from the [**schrute**](https://bradlindblad.github.io/schrute/) package to predict IMDB scores for episodes of The Office.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(theoffice)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 55,130\nColumns: 12\n$ index            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16…\n$ season           <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ episode          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ episode_name     <chr> \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\", \"Pilot\",…\n$ director         <chr> \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis\", \"Ken Kwapis…\n$ writer           <chr> \"Ricky Gervais;Stephen Merchant;Greg Daniels\", \"Ricky…\n$ character        <chr> \"Michael\", \"Jim\", \"Michael\", \"Jim\", \"Michael\", \"Micha…\n$ text             <chr> \"All right Jim. Your quarterlies look very good. How …\n$ text_w_direction <chr> \"All right Jim. Your quarterlies look very good. How …\n$ imdb_rating      <dbl> 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6…\n$ total_votes      <int> 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706, 3706,…\n$ air_date         <chr> \"2005-03-24\", \"2005-03-24\", \"2005-03-24\", \"2005-03-24…\n```\n\n\n:::\n:::\n\n\nFix `air_date` for later use.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheoffice <- theoffice %>%\n  mutate(air_date = ymd(as.character(air_date)))\n```\n:::\n\n\nWe will\n\n-   engineer features based on episode scripts\n-   train a model\n-   perform cross validation\n-   make predictions\n\nNote: The episodes listed in `theoffice` don't match the ones listed in the data we used in the [cross validation lesson](https://ids-s1-20.github.io/slides/week-10/w10-d02-cross-validation/w10-d02-cross-validation.html).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheoffice %>%\n  distinct(season, episode)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 186 × 2\n   season episode\n    <int>   <int>\n 1      1       1\n 2      1       2\n 3      1       3\n 4      1       4\n 5      1       5\n 6      1       6\n 7      2       1\n 8      2       2\n 9      2       3\n10      2       4\n# ℹ 176 more rows\n```\n\n\n:::\n:::\n\n\n### Exercise 1 - Calculate the percentage of lines spoken by Jim, Pam, Michael, and Dwight for each episode of The Office.\n\n\n::: {.cell}\n\n:::\n\n\n### Exercise 2 - Identify episodes that touch on Halloween, Valentine's Day, and Christmas.\n\n\n::: {.cell}\n\n:::\n\n\n### Exercise 3 - Put together a modeling dataset that includes features you've engineered. Also add an indicator variable called `michael` which takes the value `1` if Michael Scott (Steve Carrell) was there, and `0` if not. Note: Michael Scott (Steve Carrell) left the show at the end of Season 7.\n\n\n::: {.cell}\n\n:::\n\n\n### Exercise 4 - Split the data into training (75%) and testing (25%).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1122)\n```\n:::\n\n\n### Exercise 5 - Specify a linear regression model.\n\n\n::: {.cell}\n\n:::\n\n\n### Exercise 6 - Create a recipe that updates the role of `episode_name` to not be a predictor, removes `air_date` as a predictor, uses `season` as a factor, and removes all zero variance predictors.\n\n\n::: {.cell}\n\n:::\n\n\n### Exercise 7 - Build a workflow for fitting the model specified earlier and using the recipe you developed to preprocess the data.\n\n\n::: {.cell}\n\n:::\n\n\n### Exercise 8 - Fit the model to training data and interpret a couple of the slope coefficients.\n\n\n::: {.cell}\n\n:::\n\n\n### Exercise 9 - Perform 5-fold cross validation and view model performance metrics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#set.seed(345)\n#folds <- vfold_cv(___, v = ___)\n#folds\n#\n#set.seed(456)\n#office_fit_rs <- ___ %>%\n#  ___(___)\n#\n#___(office_fit_rs)\n```\n:::\n\n\n### Exercise 10 - Use your model to make predictions for the testing data and calculate the RMSE. Also use the model developed in the [cross validation lesson](https://ids-s1-20.github.io/slides/week-10/w10-d02-cross-validation/w10-d02-cross-validation.html) to make predictions for the testing data and calculate the RMSE as well. Which model did a better job in predicting IMDB scores for the testing data?\n\n#### New model\n\n\n::: {.cell}\n\n:::\n\n\n#### Old model\n\nTO DO: See what `___` is.\n\n````r\n#| label: old-model\n#| error: true\n\noffice_mod_old <- linear_reg() %>%\n  set_engine(\"lm\")\n\noffice_rec_old <- recipe(imdb_rating ~ season + episode + total_votes + air_date, data = office_train) %>%\n  # extract month of air_date\n  step_date(air_date, features = \"month\") %>%\n  step_rm(air_date) %>%\n  # make dummy variables of month \n  step_dummy(contains(\"month\")) %>%\n  # remove zero variance predictors\n  step_zv(all_predictors())\n\noffice_wflow_old <- workflow() %>%\n  add_model(office_mod_old) %>%\n  add_recipe(office_rec_old)\n\noffice_fit_old <- office_wflow_old %>%\n  fit(data = office_train)\n\ntidy(office_fit_old)\n\n___\n````\n",
    "supporting": [
      "theoffice_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
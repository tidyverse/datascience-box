<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Model validation and logistic regression   ✅</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <link rel="stylesheet" href="../slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Model validation and logistic regression <br> ✅
### 

---





layout: true
  
&lt;div class="my-footer"&gt;
&lt;span&gt;
&lt;a href="https://datasciencebox.org" target="_blank"&gt;datasciencebox.org&lt;/a&gt;
&lt;/span&gt;
&lt;/div&gt; 

---



class: middle

# From last time

---

.small[

```r
full_model &lt;- lm(score ~ rank + ethnicity + gender + language + 
                         age + cls_perc_eval + cls_did_eval + 
                         cls_students + cls_level + cls_profs + 
                         cls_credits + bty_avg, data = evals)

selected_model &lt;- step(full_model, direction = "backward")
```

```
## Start:  AIC=-620.19
## score ~ rank + ethnicity + gender + language + age + cls_perc_eval + 
##     cls_did_eval + cls_students + cls_level + cls_profs + cls_credits + 
##     bty_avg
## 
##                 Df Sum of Sq    RSS     AIC
## - rank           2    0.3928 114.57 -622.60
## - cls_profs      1    0.0024 114.18 -622.18
## - cls_level      1    0.0085 114.19 -622.16
## - cls_students   1    0.0588 114.24 -621.95
## - cls_did_eval   1    0.1314 114.31 -621.66
## - language       1    0.3661 114.54 -620.71
## &lt;none&gt;                       114.18 -620.19
## - age            1    1.1513 115.33 -617.54
## - cls_perc_eval  1    1.2535 115.43 -617.13
## - ethnicity      1    1.4231 115.60 -616.46
## - gender         1    3.1276 117.30 -609.68
## - bty_avg        1    3.3878 117.56 -608.65
## - cls_credits    1    4.7526 118.93 -603.31
## 
## Step:  AIC=-622.6
## score ~ ethnicity + gender + language + age + cls_perc_eval + 
##     cls_did_eval + cls_students + cls_level + cls_profs + cls_credits + 
##     bty_avg
## 
##                 Df Sum of Sq    RSS     AIC
## - cls_level      1    0.0020 114.57 -624.59
## - cls_profs      1    0.0037 114.57 -624.59
## - cls_students   1    0.0890 114.66 -624.24
## - cls_did_eval   1    0.1710 114.74 -623.91
## &lt;none&gt;                       114.57 -622.60
## - language       1    0.5680 115.14 -622.31
## - age            1    0.8990 115.47 -620.98
## - cls_perc_eval  1    1.2154 115.78 -619.71
## - ethnicity      1    1.6286 116.20 -618.06
## - gender         1    3.2321 117.80 -611.72
## - bty_avg        1    3.5172 118.09 -610.60
## - cls_credits    1    5.6074 120.18 -602.48
## 
## Step:  AIC=-624.59
## score ~ ethnicity + gender + language + age + cls_perc_eval + 
##     cls_did_eval + cls_students + cls_profs + cls_credits + bty_avg
## 
##                 Df Sum of Sq    RSS     AIC
## - cls_profs      1    0.0034 114.58 -626.58
## - cls_students   1    0.1012 114.67 -626.18
## - cls_did_eval   1    0.1862 114.76 -625.84
## &lt;none&gt;                       114.57 -624.59
## - language       1    0.5710 115.14 -624.29
## - age            1    0.8977 115.47 -622.98
## - cls_perc_eval  1    1.2223 115.79 -621.68
## - ethnicity      1    1.6628 116.23 -619.92
## - gender         1    3.2311 117.80 -613.72
## - bty_avg        1    3.5152 118.09 -612.60
## - cls_credits    1    6.1340 120.71 -602.44
## 
## Step:  AIC=-626.58
## score ~ ethnicity + gender + language + age + cls_perc_eval + 
##     cls_did_eval + cls_students + cls_credits + bty_avg
## 
##                 Df Sum of Sq    RSS     AIC
## - cls_students   1    0.1045 114.68 -628.16
## - cls_did_eval   1    0.1921 114.77 -627.80
## &lt;none&gt;                       114.58 -626.58
## - language       1    0.5710 115.15 -626.28
## - age            1    0.9013 115.48 -624.95
## - cls_perc_eval  1    1.2242 115.80 -623.66
## - ethnicity      1    1.7458 116.32 -621.58
## - gender         1    3.2310 117.81 -615.70
## - bty_avg        1    3.5121 118.09 -614.60
## - cls_credits    1    6.3135 120.89 -603.74
## 
## Step:  AIC=-628.16
## score ~ ethnicity + gender + language + age + cls_perc_eval + 
##     cls_did_eval + cls_credits + bty_avg
## 
##                 Df Sum of Sq    RSS     AIC
## - cls_did_eval   1    0.4446 115.12 -628.36
## &lt;none&gt;                       114.68 -628.16
## - language       1    0.5418 115.22 -627.97
## - age            1    0.8836 115.56 -626.60
## - ethnicity      1    1.8576 116.54 -622.72
## - gender         1    3.1442 117.82 -617.63
## - bty_avg        1    3.5015 118.18 -616.23
## - cls_perc_eval  1    3.5358 118.22 -616.10
## - cls_credits    1    6.2995 120.98 -605.40
## 
## Step:  AIC=-628.36
## score ~ ethnicity + gender + language + age + cls_perc_eval + 
##     cls_credits + bty_avg
## 
##                 Df Sum of Sq    RSS     AIC
## &lt;none&gt;                       115.12 -628.36
## - language       1    0.6192 115.74 -627.88
## - age            1    0.9342 116.06 -626.62
## - ethnicity      1    1.8997 117.02 -622.79
## - cls_perc_eval  1    3.1769 118.30 -617.76
## - gender         1    3.4709 118.59 -616.61
## - bty_avg        1    4.0096 119.13 -614.51
## - cls_credits    1    6.1046 121.23 -606.44
```
]

---

class: middle

# Model validation

---

## Overfitting

- The data we are using to construct our models come from a larger population.
- Ultimately we want our model to tell us how the population works, not just the sample we have.
- If the model we fit is too tailored to our sample, it might not perform as well with the remaining population. This means the model is "overfitting" our data.
- We measure this using **model validation** techniques.
- Note: Overfitting is not a huge concern with linear models with low level 
interactions, however it can be with more complex and flexible models. The 
following is just an example of model validation, even though we're using it 
in a scenario where the concern for overfitting is not high.

---

## Model validation

- One commonly used model validation technique is to partition your data 
into training and testing set
- That is, fit the model on the training data
- And test it on the testing data
- Evaluate model performance using `\(RMSE\)`, root-mean squared error

$$ RMSE = \sqrt{\frac{\sum_{i = 1}^n (y_i - \hat{y}_i)^2}{n}} $$

.question[
Do you think we should prefer low or high RMSE?
]

---

## Random sampling and reproducibility

Gotta set a seed!


```r
set.seed(3518)
```

- We will be taking random samples, but we want the analysis to be 
reproducible (across different people running the sama analysis as well as 
for the same person running the analysis at different times)
- So we need to tell R where to start the (pseudo) random number generation



---

## Cross validation

More specifically, **k-fold cross validation**:

- Split your data into k folds
- Use 1 fold for testing and the remaining (k - 1) folds for training
- Repeat k times

---

## Aside -- the modulo operator


```r
9 %% 5
```

```
## [1] 4
```

--

.pull-left[

```
## # A tibble: 8 x 2
##     obs  fold
##   &lt;int&gt; &lt;int&gt;
## 1     1     1
## 2     2     2
## 3     3     3
## 4     4     4
## 5     5     5
## 6     6     1
## # … with 2 more rows
```
]

--

.pull-right[
.midi[

```r
(1:8) %% 5
```

```
## [1] 1 2 3 4 0 1 2 3
```

```r
((1:8) - 1) %% 5
```

```
## [1] 0 1 2 3 4 0 1 2
```

```r
(((1:8) - 1) %% 5) + 1
```

```
## [1] 1 2 3 4 5 1 2 3
```
]
]

---

## Prepping your data for 5-fold CV


```r
evals_cv &lt;- evals %&gt;%
  sample_n(nrow(evals)) %&gt;%               # scramble rows
  rowid_to_column() %&gt;%                   # add id column
  mutate( fold = ((rowid - 1) %% 5) + 1 ) # add fold column

evals_cv %&gt;% 
  count(fold)
```

```
## # A tibble: 5 x 2
##    fold     n
##   &lt;dbl&gt; &lt;int&gt;
## 1     1    93
## 2     2    93
## 3     3    93
## 4     4    92
## 5     5    92
```

---

## CV 1


```r
test_fold &lt;- 1
test &lt;- evals_cv %&gt;% filter(fold == test_fold)
train &lt;- evals_cv %&gt;% filter(fold != test_fold)
mod &lt;- lm(score ~ ethnicity + gender + language + age + cls_perc_eval + 
    cls_credits + bty_avg, data = train)
(rmse_test1 &lt;- rmse(mod, test))
```

```
## [1] 0.5145416
```

---

## RMSE on training vs. testing

.question[
Would you expect the RMSE to be higher for your training data or your testing data? Why?
]

---

## RMSE on training vs. testing

RMSE for testing:
.small[

```r
(rmse_test1 &lt;- rmse(mod, test))
```

```
## [1] 0.5145416
```
]

RMSE for training:
.small[

```r
(rmse_train1 &lt;- rmse(mod, train))
```

```
## [1] 0.4955734
```
]

---

## CV 2


```r
test_fold &lt;- 2
test &lt;- evals_cv %&gt;% filter(fold == test_fold)
train &lt;- evals_cv %&gt;% filter(fold != test_fold)
mod &lt;- lm(score ~ ethnicity + gender + language + age + cls_perc_eval + 
    cls_credits + bty_avg, data = train)
```


```r
(rmse_test2 &lt;- rmse(mod, test))
```

```
## [1] 0.54365
```

```r
(rmse_train2 &lt;- rmse(mod, train))
```

```
## [1] 0.4885794
```

---

## CV 3


```r
test_fold &lt;- 3
test &lt;- evals_cv %&gt;% filter(fold == test_fold)
train &lt;- evals_cv %&gt;% filter(fold != test_fold)
mod &lt;- lm(score ~ ethnicity + gender + language + age + cls_perc_eval + 
    cls_credits + bty_avg, data = train)
```


```r
(rmse_test3 &lt;- rmse(mod, test))
```

```
## [1] 0.495042
```

```r
(rmse_train3 &lt;- rmse(mod, train))
```

```
## [1] 0.501638
```

---

## CV 4


```r
test_fold &lt;- 4
test &lt;- evals_cv %&gt;% filter(fold == test_fold)
train &lt;- evals_cv %&gt;% filter(fold != test_fold)
mod &lt;- lm(score ~ ethnicity + gender + language + age + cls_perc_eval + 
    cls_credits + bty_avg, data = train)
```


```r
(rmse_test4 &lt;- rmse(mod, test))
```

```
## [1] 0.5164751
```

```r
(rmse_train4 &lt;- rmse(mod, train))
```

```
## [1] 0.4956894
```

---

## CV 5


```r
test_fold &lt;- 5
test &lt;- evals_cv %&gt;% filter(fold == test_fold)
train &lt;- evals_cv %&gt;% filter(fold != test_fold)
mod &lt;- lm(score ~ ethnicity + gender + language + age + cls_perc_eval + 
    cls_credits + bty_avg, data = train)
```


```r
(rmse_test5 &lt;- rmse(mod, test))
```

```
## [1] 0.4784781
```

```r
(rmse_train5 &lt;- rmse(mod, train))
```

```
## [1] 0.5052505
```

---

## Putting it altogether

&lt;img src="u2_d06-model-validation_files/figure-html/unnamed-chunk-19-1.png" width="100%" style="display: block; margin: auto;" /&gt;

---

## How does RMSE compare to y?

- `score` summary stats:


```
## # A tibble: 1 x 6
##     min   max  mean   med    sd   IQR
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1   2.3     5  4.17   4.3 0.544 0.800
```

- `rmse_test` summary stats:


```
## # A tibble: 1 x 6
##     min   max  mean   med     sd    IQR
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 0.478 0.544 0.510 0.515 0.0246 0.0214
```

---

class: middle

# Prediction

---

## New observation

To make a prediction for a new observation we need to create a data frame with that observation.

.question[
Suppose we want to make a prediction for a 37 year old white woman professor who received her education at an English speaking country and who teaches a multi credit course. 80% of her classes tend to fill out evaluations, and she's average looiking (beauty score = 2.5).

The following won't work. Why? How would you correct it?
]


```r
new_prof &lt;- data_frame(ethnicity = "white",
                       sex = "woman",
                       language = "English",
                       age = 35, 
                       cls_perc_eval = 0.80,
                       cls_credits = "multi-credit",
                       bty_avg = 2.5)
```

---

## New observation, corrected


```r
new_prof &lt;- data_frame(ethnicity = "not minority",
                       gender = "female",
                       language = "english",
                       age = 35, 
                       cls_perc_eval = 0.80,
                       cls_credits = "multi credit",
                       bty_avg = 2.5)
```

---

## Prediction


```r
predict(selected_model, newdata = new_prof)
```

```
##        1 
## 3.642979
```

---

## Uncertainty around prediction

Prediction interval around `\(\hat{y}\)` for new data (score for a prof with given characteristics):


```r
predict(selected_model, newdata = new_prof, interval = "prediction")
```

```
##        fit      lwr     upr
## 1 3.642979 2.626498 4.65946
```
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightLines": true,
"highlightStyle": "solarized-light",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>

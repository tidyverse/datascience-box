---
title: "Web scraping <br> `r emo::ji('spider_web')`"
author: ""
output:
  xaringan::moon_reader:
    css: "../slides.css"
    lib_dir: libs
    nature:
      ratio: "16:9"
      highlightLines: true
      highlightStyle: solarized-light
      countIncrementalSlides: false
---

```{r child = "../setup.Rmd"}
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(scales)
library(here)
library(rvest)
library(DT)
```

class: middle

# Scraping the web

---

## Scraping the web: what? why?

- Increasing amount of data is available on the web
--

- These data are provided in an unstructured format: you can always copy&paste, 
but it's time-consuming and prone to errors

--
- Web scraping is the process of extracting this information automatically and transform it into a structured dataset

--
- Two different scenarios:
    - Screen scraping: extract data from source code of website, with html 
    parser (easy) or regular expression matching (less easy).
    - Web APIs (application programming interface): website offers a set of 
    structured http requests that return JSON or XML files.

---

class: middle

# Web Scraping with rvest

---

## Hypertext Markup Language

- Most of the data on the web is still largely available as HTML 
- It is structured (hierarchical / tree based), but it''s often not available in 
a form useful for analysis (flat / tidy).

```html
<html>
  <head>
    <title>This is a title</title>
  </head>
  <body>
    <p align="center">Hello world!</p>
  </body>
</html>
```

---

## rvest

.pull-left[
- The **rvest** package makes basic processing and manipulation of HTML data straight forward
- It's designed to work with pipelines built with `%>%`
]
.pull-right[
```{r echo=FALSE,out.width=230,fig.align="right"}
knitr::include_graphics("img/rvest.png")
```
]

---

## Core rvest functions

- `read_html`   - Read HTML data from a url or character string
- `html_node `  - Select a specified node from HTML document
- `html_nodes`  - Select specified nodes from HTML document
- `html_table`  - Parse an HTML table into a data frame
- `html_text`   - Extract tag pairs' content
- `html_name`   - Extract tags' names
- `html_attrs`  - Extract all of each tag's attributes
- `html_attr`   - Extract tags' attribute value by name

---

## SelectorGadget

.pull-left[
- Open source tool that eases CSS selector generation and discovery
- Easiest to use with the [Chrome Extension](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb) 
- Find out more on the [SelectorGadget vignette](https://cran.r-project.org/web/packages/rvest/vignettes/selectorgadget.html)
]
.pull-right[
```{r echo=FALSE}
knitr::include_graphics("img/selector-gadget.png")
```
]

---

## Using the SelectorGadget

.pull-left[
- Click on the app logo next to the search bar
- A box will open in the bottom right of the website
]
.pull-right[
```{r echo=FALSE,fig.align="center",out.height=250}
knitr::include_graphics("img/selector-gadget.gif")
```
]

--

- Click on a page element (it will turn green), SelectorGadget will generate a 
minimal CSS selector for that element, and will highlight (yellow) everything 
that is matched by the selector

--
- Click on a highlighted element to remove it from the selector (red), or 
click on an unhighlighted element to add it to the selector

--
- Through this process of selection and rejection, SelectorGadget helps you come 
up with the appropriate CSS selector for your needs


---

class: middle

# Top 250 movies on IMDB

---

## Top 250 movies on IMDB

Take a look at the source code, look for the tag `table` tag:
<br>
http://www.imdb.com/chart/top

![imdb_top](img/imdb_top_250.png)

---

## First check if you're allowed!

```{r warning=FALSE}
library(robotstxt)
paths_allowed("http://www.imdb.com")
```

vs. e.g.

```{r warning=FALSE}
paths_allowed("http://www.facebook.com")
```


---

.your-turn[
- [RStudio Cloud](http://rstd.io/dsbox-cloud) > `AE 08 - IMDB + Webscraping`.
- Open `01-imdb-250movies.R`.
- Follow along, and fill in the blanks as we go based on upcoming slides.
]

---

## Select and format pieces

.small[
```{r message=FALSE, cache=TRUE}
page <- read_html("http://www.imdb.com/chart/top")

titles <- page %>%
  html_nodes(".titleColumn a") %>%
  html_text()

years <- page %>%
  html_nodes(".secondaryInfo") %>%
  html_text() %>%
  str_replace("\\(", "") %>% # remove (
  str_replace("\\)", "") %>% # remove )
  as.numeric()

scores <- page %>%
  html_nodes("#main strong") %>%
  html_text() %>%
  as.numeric()
  
imdb_top_250 <- tibble(
  title = titles, 
  year = years, 
  score = scores
  )
```
]

---

```{r echo=FALSE}
imdb_top_250 %>% datatable(options(list(dom = "p", pageLength = 8)), height = 400)
```

---

## Clean up / enhance

May or may not be a lot of work depending on how messy the data are

- See if you like what you got:

```{r}
glimpse(imdb_top_250)
```

- Add a variable for rank
```{r}
imdb_top_250 <- imdb_top_250 %>%
  mutate(rank = 1:nrow(imdb_top_250))
```

---

```{r echo=FALSE}
imdb_top_250 %>% datatable(options(list(dom = "p", pageLength = 8)), height = 400)
```

---

## Analyze

.question[
How would you go about answering this question: Which 1995 movies made the list?
]

--

```{r}
imdb_top_250 %>% 
  filter(year == 1995)
```

---

## Analyze

.question[
How would you go about answering this question: Which years have the most movies on the list?
]

--

```{r}
imdb_top_250 %>% 
  group_by(year) %>%
  summarise(total = n()) %>%
  arrange(desc(total)) %>%
  head(5)
```

---

## Visualize

.question[
How would you go about creating this visualization: Visualize the average yearly score for movies that made it on the top 250 list over time.
]

--

.small[
```{r echo=FALSE, out.width="90%"}
imdb_top_250 %>% 
  group_by(year) %>%
  summarise(avg_score = mean(score)) %>%
  ggplot(aes(y = avg_score, x = year)) +
    geom_point() +
    geom_smooth(method = "lm") +
    labs(x = "Year", y = "Average score")
```
]

---

## Potential challenges

- Unreliable formatting at the source
- Data broken into many pages
- ...

.question[
Compare the display of information at [gumtree.com/cars-vans-motorbikes/edinburgh](https://www.gumtree.com/cars-vans-motorbikes/edinburgh) to the list on the IMDB top 250 list. What challenges can you foresee in scraping a list of the available apartments?
]

---

.your-turn[
- [RStudio Cloud](http://rstd.io/dsbox-cloud) > `AE 08 - IMDB + Webscraping`.
- Open `02-imdb-tvshows.R`.
- Scrape the names, scores, and years of most popular TV shows on IMDB:
[www.imdb.com/chart/tvmeter](http://www.imdb.com/chart/tvmeter).
- Create a data frame called `tvshows` with four variables: `rank`, `name`, `score`, `year`.
- Examine each of the **first three** TV shows to also obtain genre, runtime, how many episodes so far, first five plot keywords.
- Add this information to the `tvshows` data frame you created earlier.
]
